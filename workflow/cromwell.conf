# See https://cromwell.readthedocs.io/en/stable/Configuring/
# this configuration only accepts double quotes! not singule quotes
include required(classpath("application"))

system {
  abort-jobs-on-terminate = true
  io {
    number-of-requests = 30
    per = 1 second
  }
  file-hash-cache = true
}

# necessary for call result caching
# will need to stand up the MySQL server each time before running cromwell
# stand it up on the same node that's running cromwell
database {
  profile = "slick.jdbc.MySQLProfile$"
  db {
    driver = "com.mysql.cj.jdbc.Driver"
    url = "jdbc:mysql://localhost/cromwell?rewriteBatchedStatements=true"
    user = "root"
    password = "pass"
    connectionTimeout = 5000
  }
}

### file based persistent database
# the implementation here proved to be poorly designed and so much too slow
#database {
#  profile = "slick.jdbc.HsqldbProfile$"
#  db {
#    driver = "org.hsqldb.jdbcDriver"
#    url = """
#    jdbc:hsqldb:file:cromwell-executions/cromwell-db/cromwell-db;
#    shutdown=false;
#    hsqldb.default_table_type=cached;hsqldb.tx=mvcc;
#    hsqldb.result_max_memory_rows=10000;
#    hsqldb.large_data=true;
#    hsqldb.applog=1;
#    hsqldb.lob_compressed=true;
#    hsqldb.script_format=3
#    """
#    connectionTimeout = 120000
#    numThreads = 1
#   }
#}

call-caching {
  enabled = true
  invalidate-bad-cache-results = true
}

docker {
  hash-lookup {
    enabled = true
    method = "remote"
  }
}

workflow-options {
  workflow-log-dir = "cromwell-workflow-logs"
  workflow-log-temporary = false
}

backend {
  # which backend do you want to use?
  # Right now I don't know how to choose this via command line, only here
  default = "Local" # For running jobs on an interactive node
  #default = "SLURM" # For running jobs by submitting them from an interactive node to the cluster
  providers {  
    # For running jobs on an interactive node
    Local {
      actor-factory = "cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"
      config {
        concurrent-job-limit = 10
        run-in-background = true
        root = "cromwell-executions"
        dockerRoot = "/cromwell-executions"
        runtime-attributes = """
          String? docker
        """
        submit = "/usr/bin/env bash ${script}"

        # We're asking bash-within-singularity to run the script, but the script's location on the machine
        # is different then the location its mounted to in the container, so need to change the path with sed
        submit-docker = """
          singularity exec --containall --bind ${cwd}:${docker_cwd} docker://${docker} bash \
               "$(echo ${script} | sed -e 's@.*cromwell-executions@/cromwell-executions@')"
        """
        filesystems {
          local {
            localization: ["hard-link"]
            caching {
              duplication-strategy: ["hard-link"]
              hashing-strategy: "fingerprint"
              check-sibling-md5: true
              fingerprint-size: 1048576 # 1 MB 
            }
          }
        }
      }
    }
    # For running jobs by submitting them from an interactive node to the cluster
    SLURM {
      actor-factory = "cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"
      config {
        concurrent-job-limit = 500
        root = "cromwell-executions"
        dockerRoot = "/cromwell-executions"

        runtime-attributes = """
          Int cpus = 1
          String mem = "2g"
          String dx_timeout
          String? docker
        """
        check-alive = "squeue -j ${job_id}"
        exit-code-timeout-seconds = 500
        job-id-regex = "Submitted batch job (\\d+).*"

        submit = """
          sbatch \
            --account ddp268 \
            --partition ind-shared \
            --nodes 1 \
            --job-name=${job_name} \
            -o ${out} -e ${err}  \
            --mail-type FAIL --mail-user jonathan.margoliash@gmail.com \
            --ntasks-per-node=${cpus} \
            --mem=${mem} \
            -c ${cpus} \
            --time=$(echo ${dx_timeout} | sed -e 's/ //g' -e 's/\([0-9]\+\)h\([0-9]\+\)m/\1:\2:00/' -e 's/\([0-9]\+\)h/\1:00:00/' -e 's/\([0-9]\+\)m/\1:00/') \
            --chdir ${cwd} \
            --wrap "/bin/bash ${script}"
        """
        kill = "scancel ${job_id}"

        # We're asking bash-within-singularity to run the script, but the script's location on the machine
        # is different then the location its mounted to in the container, so need to change the path with sed
        submit-docker = """
          sbatch \
            --account ddp268 \
            --partition ind-shared \
            --nodes 1 \
            --job-name=${job_name} \
            -o ${out} -e ${err}  \
            --mail-type FAIL --mail-user jonathan.margoliash@gmail.com \
            --ntasks-per-node=${cpus} \
            --mem=${mem} \
            -c ${cpus} \
            --time=$(echo ${dx_timeout} | sed -e 's/ //g' -e 's/\([0-9]\+\)h\([0-9]\+\)m/\1:\2:00/' -e 's/\([0-9]\+\)h/\1:00:00/' -e 's/\([0-9]\+\)m/\1:00/') \
            --chdir ${cwd} \
            --wrap "
              singularity exec --containall --bind ${cwd}:${docker_cwd} docker://${docker} bash \
                   \"$(echo ${script} | sed -e 's@.*cromwell-executions@/cromwell-executions@')\"
            "
        """
        kill-docker = "scancel ${job_id}"

        filesystems {
          local {
            localization: ["hard-link"]
            caching {
              duplication-strategy: ["hard-link"]
              check-sibling-md5: true
              hashing-strategy: "fingerprint"
              fingerprint-size: 1048576 # 1 MB 
            }
          }
        }

      }
    }
}}
